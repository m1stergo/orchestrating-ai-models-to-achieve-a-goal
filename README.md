# Orchestrating AI Models - Microservices Architecture

Este proyecto implementa una arquitectura de microservicios para orquestar modelos de IA, separando las funcionalidades en servicios independientes para optimizar el despliegue y escalabilidad.

## ğŸ—ï¸ Arquitectura

```
Frontend (Vue.js)
       â†“
Core Backend (FastAPI) â† API Gateway
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Microservicios             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ describe-image-service    (Puerto 8001) â”‚ â† GPU Intensivo (RunPod)
â”‚ extract-webcontent-service (Puerto 8002) â”‚ â† CPU (Servidor estÃ¡ndar)
â”‚ generate-description-service (Puerto 8003) â”‚ â† GPU/CPU (RunPod/EstÃ¡ndar)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
PostgreSQL Database
```

## ğŸ“ Estructura del Monorepo

```
orchestrating-ai-models/
â”œâ”€â”€ backend/              # Backend principal (CRUD, Gateway)
â”‚   â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ services/                  # Microservicios AI
â”‚   â”œâ”€â”€ describe-image/        # AnÃ¡lisis de imÃ¡genes con Qwen2.5-VL
â”‚   â”œâ”€â”€ extract-webcontent/    # ExtracciÃ³n de contenido web
â”‚   â””â”€â”€ generate-description/  # GeneraciÃ³n de descripciones
â”œâ”€â”€ shared/                    # CÃ³digo compartido
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ config/
â”œâ”€â”€ frontend/                  # Interfaz Vue.js
â”œâ”€â”€ docker-compose.yml         # Desarrollo local
â””â”€â”€ .github/workflows/         # CI/CD pipelines
```

## ğŸš€ Despliegue por Servicios

### Desarrollo Local (Docker)

```bash
# Iniciar todos los servicios
docker-compose up -d

# Servicios disponibles:
# - Core Backend: http://localhost:8000
# - Describe Image: http://localhost:8001
# - Extract WebContent: http://localhost:8002
# - Generate Description: http://localhost:8003
# - PostgreSQL: localhost:5432
```

### ProducciÃ³n (RunPod + Servidores)

**Backend** â†’ Servidor estÃ¡ndar (DigitalOcean, AWS, etc.)
```bash
# Variables de entorno para producciÃ³n
DESCRIBE_IMAGE_SERVICE_URL=https://describe-image.runpod.io
EXTRACT_WEBCONTENT_SERVICE_URL=https://extract-web.yourserver.com
GENERATE_DESCRIPTION_SERVICE_URL=https://generate-desc.runpod.io
```

**Servicios AI** â†’ RunPod (GPU) o servidores estÃ¡ndar (CPU)

## ğŸ”§ ConfiguraciÃ³n por Servicio

### Backend (Puerto 8000)
- **FunciÃ³n**: API Gateway, CRUD productos, upload imÃ¡genes
- **Recursos**: CPU estÃ¡ndar, base de datos
- **Despliegue**: Cualquier proveedor cloud

### Describe Image Service (Puerto 8001)
- **FunciÃ³n**: AnÃ¡lisis de imÃ¡genes con Qwen2.5-VL
- **Recursos**: GPU (NVIDIA RTX 4090 recomendada)
- **Despliegue**: RunPod con GPU

### Extract WebContent Service (Puerto 8002)
- **FunciÃ³n**: Scraping y extracciÃ³n de contenido web
- **Recursos**: CPU, memoria para Selenium
- **Despliegue**: Servidor estÃ¡ndar

### Generate Description Service (Puerto 8003)
- **FunciÃ³n**: GeneraciÃ³n de descripciones con LLMs
- **Recursos**: GPU (opcional) o CPU con APIs externas
- **Despliegue**: RunPod (GPU) o servidor estÃ¡ndar (API)

## ğŸ› ï¸ Desarrollo

### Ejecutar un servicio individual

```bash
# Describe Image Service
cd services/describe-image
pip install -r requirements.txt
uvicorn main:app --host 0.0.0.0 --port 8001

# Extract WebContent Service
cd services/extract-webcontent
pip install -r requirements.txt
uvicorn main:app --host 0.0.0.0 --port 8002

# Generate Description Service
cd services/generate-description
pip install -r requirements.txt
uvicorn main:app --host 0.0.0.0 --port 8003
```

### Construir imÃ¡genes Docker individuales

```bash
# Backend
docker build -t backend ./backend

# Servicios AI
docker build -t describe-image-service ./services/describe-image
docker build -t extract-webcontent-service ./services/extract-webcontent
docker build -t generate-description-service ./services/generate-description
```

## ğŸ”„ CI/CD con GitHub Actions

Cada servicio tiene su propio workflow que se activa cuando hay cambios:

- **build-backend.yml** â†’ Cambios en `backend/`
- **build-describe-image.yml** â†’ Cambios en `services/describe-image/`
- **build-extract-webcontent.yml** â†’ Cambios en `services/extract-webcontent/`
- **build-generate-description.yml** â†’ Cambios en `services/generate-description/`

Los workflows automÃ¡ticamente:
1. Construyen la imagen Docker
2. La suben a GitHub Container Registry
3. Despliegan a producciÃ³n (RunPod/servidor)

## ğŸŒ Endpoints de Servicios

### Backend (Gateway)
```
POST /api/v1/services/describe-image
POST /api/v1/services/extract-webcontent
POST /api/v1/services/generate-description
GET  /api/v1/services/health
```

### Servicios Directos
```
# Describe Image Service
POST http://localhost:8001/api/v1/describe
GET  http://localhost:8001/health

# Extract WebContent Service
POST http://localhost:8002/api/v1/extract
GET  http://localhost:8002/health

# Generate Description Service
POST http://localhost:8003/api/v1/generate
GET  http://localhost:8003/health
```

## ğŸ”‘ Variables de Entorno

### Backend
```env
DATABASE_URL=postgresql://postgres:postgres@postgres:5432/orchestration_db
DESCRIBE_IMAGE_SERVICE_URL=http://describe-image-service:8001
EXTRACT_WEBCONTENT_SERVICE_URL=http://extract-webcontent-service:8002
GENERATE_DESCRIPTION_SERVICE_URL=http://generate-description-service:8003
```

### Servicios AI
```env
# Para Generate Description Service
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key

# Para Describe Image Service
MODEL_CACHE_DIR=/app/models
```

## ğŸ“Š Ventajas de esta Arquitectura

âœ… **Escalabilidad independiente** - Cada servicio puede escalar segÃºn demanda
âœ… **Despliegue optimizado** - GPU solo donde se necesita
âœ… **Tolerancia a fallos** - Un servicio caÃ­do no afecta los otros
âœ… **Desarrollo paralelo** - Equipos pueden trabajar en servicios independientes
âœ… **Costos optimizados** - Pagar GPU solo para servicios que la requieren
âœ… **CI/CD granular** - Deploy solo lo que cambiÃ³

## ğŸš€ PrÃ³ximos Pasos

1. Configurar secretos en GitHub (API keys, RunPod tokens)
2. Personalizar workflows de deployment
3. Configurar monitoring y logging
4. Implementar service discovery (opcional)
5. Agregar tests automatizados por servicio