services:
  # Production service with external storage mount
  qwen:
    build:
      context: .
      dockerfile: Dockerfile.prod
    ports:
      - "8001:8001"
    runtime: nvidia
    environment:
      - MODEL_CACHE_DIR=/app/models
      - HF_HUB_CACHE=/app/models
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      # En producci√≥n, monta desde storage externo (S3, GCS, etc.)
      # Ejemplo para AWS EFS:
      # - /mnt/efs/qwen-models:/app/models:ro
      # Ejemplo para GCS Fuse:
      # - /mnt/gcs/qwen-models:/app/models:ro
      # Para desarrollo local:
      - ./models:/app/models
    user: "0:0"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

# Para desarrollo local - descarga inicial del modelo
  model-downloader:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./models:/app/models
    command: python download_model.py --cache-dir /app/models
    profiles:
      - setup  # Solo se ejecuta cuando se especifica el profile
