# Production Dockerfile for RunPod deployment
# Uses PyTorch with CUDA support for GPU acceleration
FROM pytorch/pytorch:2.8.0-cuda12.8-cudnn9-runtime

# Set working directory
WORKDIR /app

# Install system dependencies and Python tools
RUN apt-get update && apt-get install -y \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/* \
    && pip install --upgrade pip

# Copy requirements and application code
COPY requirements.txt ./
COPY app/ ./app/
COPY *.py ./

# Install dependencies from requirements.txt
RUN pip install -r requirements.txt

# Set environment variables for RunPod Network Volume (shared across services)
ENV MODEL_CACHE_DIR=/runpod-volume/models
ENV HF_HUB_CACHE=/runpod-volume/models
ENV PYTHONPATH=/app

# Create model cache directories with proper permissions (both local and RunPod)
# Create non-root user for security
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8001

# Health check (healthz for Kubernetes compatibility, status for human-readable info)
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8001/health || exit 1

# Create an entrypoint script that shows GPU info at startup
RUN printf '#!/bin/sh\necho "\\n===== GPU Information ====="\npython -c "import torch; print('"'"'CUDA Available:'"'"', torch.cuda.is_available()); print('"'"'Device Count:'"'"', torch.cuda.device_count()); print('"'"'CUDA Version:'"'"', torch.version.cuda if torch.cuda.is_available() else '"'"'N/A'"'"')"\nexec "$@"' > /app/docker-entrypoint.sh \
    && chmod +x /app/docker-entrypoint.sh

# Production command with GPU detection via entrypoint
ENTRYPOINT ["/app/docker-entrypoint.sh"]
CMD ["python", "-m", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8001"]
